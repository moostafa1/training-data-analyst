{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classifying Images with pre-built TF Container on Vertex AI\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, you learn how to implement different image models on MNIST using the [tf.keras API](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras).\n",
    "\n",
    "## Learning objectives\n",
    "1. Understand how to build a Dense Neural Network (DNN) for image classification.\n",
    "2. Understand how to use dropout (DNN) for image classification.\n",
    "3. Understand how to use Convolutional Neural Networks (CNN).\n",
    "4. Know how to deploy and use an image classifcation model using Google Cloud's [Vertex AI](https://cloud.google.com/vertex-ai/).\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in the [student lab notebook](../labs/classifying_images_with_pre-built_tf_container_on_vertex_ai.ipynb) -- try to complete that notebook first before reviewing this solution notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the parameters\n",
    "\n",
    "First, configure the parameters below to match your own Google Cloud project details.\n",
    "If you don’t want to change the region, leave all settings as they are. Otherwise, update the region as you want, leave other settings as they are and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "REGION = 'us-central1'\n",
    "PROJECT = !(gcloud config get-value core/project)\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET =  PROJECT\n",
    "MODEL_TYPE = \"cnn\"  # \"linear\", \"dnn\", \"dnn_dropout\", or \"cnn\"\n",
    "\n",
    "# Do not change these\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"MODEL_TYPE\"] = MODEL_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a dynamic model\n",
    "\n",
    "This part of notebook demonstrates how to implement DNN and CNN models on [MNIST](http://yann.lecun.com/exdb/mnist/) using the [tf.keras API](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras). \n",
    "\n",
    "In the previous notebook, “[classifying_images_with_a_nn_and_dnn_model.ipynb](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/computer_vision_fun/solutions/classifying_images_with_a_nn_and_dnn_model.ipynb)”, you run the code directly from the notebook. In this notebook, you see that you can also package your notebook as a python module on Vertex AI.\n",
    "\n",
    "The boilerplate structure for this module has already been set up in the folder mnist_models. The module lives in the sub-folder, trainer, and is designated as a python package with the empty __init__.py (mnist_models/trainer/__init__.py) file. It still needs the model and a trainer to run it, so let's make them.\n",
    "\n",
    "Start with the trainer file first. This file parses command line arguments to feed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mnist_models/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_models/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from . import model\n",
    "\n",
    "\n",
    "def _parse_arguments(argv):\n",
    "    \"\"\"Parses command-line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--model_type',\n",
    "        help='Which model type to use',\n",
    "        type=str, default='linear')\n",
    "    parser.add_argument(\n",
    "        '--epochs',\n",
    "        help='The number of epochs to train',\n",
    "        type=int, default=10)\n",
    "    parser.add_argument(\n",
    "        '--steps_per_epoch',\n",
    "        help='The number of steps per epoch to train',\n",
    "        type=int, default=100)\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help='Directory where to save the given model',\n",
    "        type=str, default='mnist_models/')\n",
    "    return parser.parse_known_args(argv)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Parses command line arguments and kicks off model training.\"\"\"\n",
    "    args = _parse_arguments(sys.argv[1:])[0]\n",
    "\n",
    "    # Configure path for hyperparameter tuning.\n",
    "    trial_id = json.loads(\n",
    "        os.environ.get('TF_CONFIG', '{}')).get('task', {}).get('trial', '')\n",
    "    output_path = args.job_dir if not trial_id else args.job_dir + '/'\n",
    "\n",
    "    model_layers = model.get_layers(args.model_type)\n",
    "    image_model = model.build_model(model_layers, args.job_dir)\n",
    "    model_history = model.train_and_evaluate(\n",
    "        image_model, args.epochs, args.steps_per_epoch, args.job_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, group non-model functions into a util file to keep the model file simple. Use the scale and load_dataset functions to scale images from a 0-255 int range to a 0-1 float range and load MNIST dataset into a tf.data.Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mnist_models/trainer/util.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_models/trainer/util.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def scale(image, label):\n",
    "    \"\"\"Scales images from a 0-255 int range to a 0-1 float range\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "        data, training=True, buffer_size=5000, batch_size=100, nclasses=10):\n",
    "    \"\"\"Loads MNIST dataset into a tf.data.Dataset\"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "    x = x_train if training else x_test\n",
    "    y = y_train if training else y_test\n",
    "    # One-hot encode the classes\n",
    "    y = tf.keras.utils.to_categorical(y, nclasses)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(scale).batch(batch_size)\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(buffer_size).repeat()\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can code the models. The tf.keras API accepts an array of layers into a model object, so you can create a dictionary of layers based on the different model types you want to use. mnist_models/trainer/model.py file has three functions: get_layers, build_model and train_and_evaluate. \n",
    "\n",
    "In get_layers function: Youl build the structure of our model in get_layers with four different layers:\n",
    "\n",
    "* First, you define a linear model.\n",
    "* Second, you define the Keras layers for a DNN model.\n",
    "* Third, you define the Keras layers for a dropout model.\n",
    "* Lastly, you define the Keras layers for a CNN model.\n",
    "\n",
    "In the build_model function: You compile the model, specifying an optimizer to use, the loss to minimize, and metrics to report. \n",
    "\n",
    "Finally in the train_and_evaluate function, you compile your Keras model by loading data into it for training.\n",
    "\n",
    "Note that these models progressively build on each other. Look at the imported tensorflow.keras.layers modules and the default values for the variables defined in get_layers for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mnist_models/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_models/trainer/model.py\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Softmax)\n",
    "\n",
    "from . import util\n",
    "\n",
    "\n",
    "# Image Variables\n",
    "WIDTH = 28\n",
    "HEIGHT = 28\n",
    "\n",
    "\n",
    "def get_layers(\n",
    "        model_type,\n",
    "        nclasses=10,\n",
    "        hidden_layer_1_neurons=400,\n",
    "        hidden_layer_2_neurons=100,\n",
    "        dropout_rate=0.25,\n",
    "        num_filters_1=64,\n",
    "        kernel_size_1=3,\n",
    "        pooling_size_1=2,\n",
    "        num_filters_2=32,\n",
    "        kernel_size_2=3,\n",
    "        pooling_size_2=2):\n",
    "    \"\"\"Constructs layers for a keras model based on a dict of model types.\"\"\"\n",
    "    model_layers = {\n",
    "        'linear': [\n",
    "            Flatten(),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        # TODO 1: Define the Keras layers for a DNN model\n",
    "        'dnn': [\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        # TODO 2: Define the Keras layers for a dropout model\n",
    "        'dnn_dropout': [\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        # TODO 3: Define the Keras layers for a CNN model\n",
    "        'cnn': [\n",
    "            Conv2D(num_filters_1, kernel_size=kernel_size_1,\n",
    "                   activation='relu', input_shape=(WIDTH, HEIGHT, 1)),\n",
    "            MaxPooling2D(pooling_size_1),\n",
    "            Conv2D(num_filters_2, kernel_size=kernel_size_2,\n",
    "                   activation='relu'),\n",
    "            MaxPooling2D(pooling_size_2),\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ]\n",
    "    }\n",
    "    return model_layers[model_type]\n",
    "\n",
    "\n",
    "def build_model(layers, output_dir):\n",
    "    \"\"\"Compiles keras model for image classification.\"\"\"\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, num_epochs, steps_per_epoch, output_dir):\n",
    "    \"\"\"Compiles keras model and loads data into it for training.\"\"\"\n",
    "    mnist = tf.keras.datasets.mnist.load_data()\n",
    "    train_data = util.load_dataset(mnist)\n",
    "    validation_data = util.load_dataset(mnist, training=False)\n",
    "\n",
    "    callbacks = []\n",
    "    if output_dir:\n",
    "        tensorboard_callback = TensorBoard(log_dir=output_dir)\n",
    "        callbacks = [tensorboard_callback]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=validation_data,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "    if output_dir:\n",
    "        export_path = os.path.join(output_dir, 'keras_export')\n",
    "        model.save(export_path, save_format='tf')\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Training\n",
    "\n",
    "After completing the set up, you can run locally to test the code. Some of the previous tests have been copied over into a testing script mnist_models/trainer/test.py to make sure the model still passes our previous checks. On line 13, you can specify which model types you would like to check. line 14 and line 15 have the number of epochs and steps per epoch respectively.\n",
    "\n",
    "Run the code below to check your models against the unit tests. If you see \"OK\" at the end when it's finished running, congrats! You've passed the tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-10 11:10:26.956391: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-01-10 11:10:27.032398: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "..\n",
      "*** Building model for linear ***\n",
      "\n",
      "Epoch 1/10\n",
      "100/100 - 6s - loss: 1.3205 - accuracy: 0.6661 - val_loss: 0.7883 - val_accuracy: 0.8210\n",
      "Epoch 2/10\n",
      "100/100 - 1s - loss: 0.6711 - accuracy: 0.8396 - val_loss: 0.5605 - val_accuracy: 0.8658\n",
      "Epoch 3/10\n",
      "100/100 - 1s - loss: 0.5260 - accuracy: 0.8742 - val_loss: 0.4689 - val_accuracy: 0.8826\n",
      "Epoch 4/10\n",
      "100/100 - 2s - loss: 0.4703 - accuracy: 0.8773 - val_loss: 0.4196 - val_accuracy: 0.8934\n",
      "Epoch 5/10\n",
      "100/100 - 1s - loss: 0.4305 - accuracy: 0.8874 - val_loss: 0.3920 - val_accuracy: 0.8960\n",
      "Epoch 6/10\n",
      "100/100 - 2s - loss: 0.3896 - accuracy: 0.8963 - val_loss: 0.3653 - val_accuracy: 0.9042\n",
      "Epoch 7/10\n",
      "100/100 - 1s - loss: 0.3758 - accuracy: 0.8976 - val_loss: 0.3520 - val_accuracy: 0.9058\n",
      "Epoch 8/10\n",
      "100/100 - 1s - loss: 0.3714 - accuracy: 0.8994 - val_loss: 0.3408 - val_accuracy: 0.9079\n",
      "Epoch 9/10\n",
      "100/100 - 1s - loss: 0.3443 - accuracy: 0.9077 - val_loss: 0.3315 - val_accuracy: 0.9095\n",
      "Epoch 10/10\n",
      "100/100 - 1s - loss: 0.3574 - accuracy: 0.9003 - val_loss: 0.3239 - val_accuracy: 0.9098\n",
      "\n",
      "*** Building model for dnn ***\n",
      "\n",
      "Epoch 1/10\n",
      "100/100 - 5s - loss: 0.5966 - accuracy: 0.8317 - val_loss: 0.2996 - val_accuracy: 0.9136\n",
      "Epoch 2/10\n",
      "100/100 - 2s - loss: 0.2474 - accuracy: 0.9297 - val_loss: 0.2354 - val_accuracy: 0.9350\n",
      "Epoch 3/10\n",
      "100/100 - 1s - loss: 0.2067 - accuracy: 0.9414 - val_loss: 0.1759 - val_accuracy: 0.9458\n",
      "Epoch 4/10\n",
      "100/100 - 2s - loss: 0.1874 - accuracy: 0.9459 - val_loss: 0.1452 - val_accuracy: 0.9570\n",
      "Epoch 5/10\n",
      "100/100 - 1s - loss: 0.1526 - accuracy: 0.9572 - val_loss: 0.1289 - val_accuracy: 0.9593\n",
      "Epoch 6/10\n",
      "100/100 - 1s - loss: 0.1382 - accuracy: 0.9630 - val_loss: 0.1239 - val_accuracy: 0.9606\n",
      "Epoch 7/10\n",
      "100/100 - 1s - loss: 0.1153 - accuracy: 0.9652 - val_loss: 0.1106 - val_accuracy: 0.9654\n",
      "Epoch 8/10\n",
      "100/100 - 1s - loss: 0.1049 - accuracy: 0.9679 - val_loss: 0.1072 - val_accuracy: 0.9673\n",
      "Epoch 9/10\n",
      "100/100 - 2s - loss: 0.0929 - accuracy: 0.9735 - val_loss: 0.0902 - val_accuracy: 0.9715\n",
      "Epoch 10/10\n",
      "100/100 - 1s - loss: 0.0893 - accuracy: 0.9726 - val_loss: 0.1087 - val_accuracy: 0.9655\n",
      "\n",
      "*** Building model for dnn_dropout ***\n",
      "\n",
      "Epoch 1/10\n",
      "100/100 - 5s - loss: 0.6451 - accuracy: 0.8088 - val_loss: 0.2746 - val_accuracy: 0.9172\n",
      "Epoch 2/10\n",
      "100/100 - 1s - loss: 0.3084 - accuracy: 0.9087 - val_loss: 0.1987 - val_accuracy: 0.9400\n",
      "Epoch 3/10\n",
      "100/100 - 1s - loss: 0.2309 - accuracy: 0.9341 - val_loss: 0.1780 - val_accuracy: 0.9460\n",
      "Epoch 4/10\n",
      "100/100 - 1s - loss: 0.2006 - accuracy: 0.9424 - val_loss: 0.1478 - val_accuracy: 0.9536\n",
      "Epoch 5/10\n",
      "100/100 - 1s - loss: 0.1570 - accuracy: 0.9551 - val_loss: 0.1440 - val_accuracy: 0.9547\n",
      "Epoch 6/10\n",
      "100/100 - 2s - loss: 0.1646 - accuracy: 0.9543 - val_loss: 0.1186 - val_accuracy: 0.9627\n",
      "Epoch 7/10\n",
      "100/100 - 2s - loss: 0.1321 - accuracy: 0.9601 - val_loss: 0.1231 - val_accuracy: 0.9601\n",
      "Epoch 8/10\n",
      "100/100 - 1s - loss: 0.1169 - accuracy: 0.9649 - val_loss: 0.1037 - val_accuracy: 0.9680\n",
      "Epoch 9/10\n",
      "100/100 - 1s - loss: 0.1121 - accuracy: 0.9676 - val_loss: 0.0924 - val_accuracy: 0.9699\n",
      "Epoch 10/10\n",
      "100/100 - 2s - loss: 0.1023 - accuracy: 0.9678 - val_loss: 0.0996 - val_accuracy: 0.9689\n",
      "\n",
      "*** Building model for cnn ***\n",
      "\n",
      "Epoch 1/10\n",
      "100/100 - 10s - loss: 0.6706 - accuracy: 0.7978 - val_loss: 0.2021 - val_accuracy: 0.9384\n",
      "Epoch 2/10\n",
      "100/100 - 8s - loss: 0.2099 - accuracy: 0.9420 - val_loss: 0.1285 - val_accuracy: 0.9602\n",
      "Epoch 3/10\n",
      "100/100 - 7s - loss: 0.1380 - accuracy: 0.9606 - val_loss: 0.0908 - val_accuracy: 0.9729\n",
      "Epoch 4/10\n",
      "100/100 - 8s - loss: 0.1041 - accuracy: 0.9683 - val_loss: 0.0600 - val_accuracy: 0.9795\n",
      "Epoch 5/10\n",
      "100/100 - 8s - loss: 0.0973 - accuracy: 0.9696 - val_loss: 0.0646 - val_accuracy: 0.9797\n",
      "Epoch 6/10\n",
      "100/100 - 8s - loss: 0.0826 - accuracy: 0.9762 - val_loss: 0.0518 - val_accuracy: 0.9834\n",
      "Epoch 7/10\n",
      "100/100 - 8s - loss: 0.0606 - accuracy: 0.9815 - val_loss: 0.0402 - val_accuracy: 0.9866\n",
      "Epoch 8/10\n",
      "100/100 - 8s - loss: 0.0622 - accuracy: 0.9821 - val_loss: 0.0387 - val_accuracy: 0.9873\n",
      "Epoch 9/10\n",
      "100/100 - 7s - loss: 0.0516 - accuracy: 0.9854 - val_loss: 0.0487 - val_accuracy: 0.9840\n",
      "Epoch 10/10\n",
      "100/100 - 8s - loss: 0.0592 - accuracy: 0.9827 - val_loss: 0.0379 - val_accuracy: 0.9874\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 138.340s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mnist_models.trainer.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know that your models are working as expected. Now ,you can run it on Google Cloud within Vertex AI. You can run it as a python module locally first using the command line.\n",
    "\n",
    "The below cell transfers some of your variables to the command line and creates a job directory including a timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_type = 'cnn'\n",
    "\n",
    "os.environ[\"MODEL_TYPE\"] = model_type\n",
    "os.environ[\"JOB_DIR\"] = \"mnist_models/models/{}_{}/\".format(\n",
    "    model_type, current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below runs the local version of the code. The epochs and steps_per_epoch flag can be changed to run for longer or shorter, as defined in your mnist_models/trainer/task.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 - 9s - loss: 1.0487 - accuracy: 0.6644 - val_loss: 0.3334 - val_accuracy: 0.8990\n",
      "Epoch 2/5\n",
      "50/50 - 5s - loss: 0.3760 - accuracy: 0.8886 - val_loss: 0.2216 - val_accuracy: 0.9332\n",
      "Epoch 3/5\n",
      "50/50 - 4s - loss: 0.2188 - accuracy: 0.9376 - val_loss: 0.1374 - val_accuracy: 0.9590\n",
      "Epoch 4/5\n",
      "50/50 - 5s - loss: 0.1550 - accuracy: 0.9534 - val_loss: 0.1135 - val_accuracy: 0.9678\n",
      "Epoch 5/5\n",
      "50/50 - 5s - loss: 0.1457 - accuracy: 0.9554 - val_loss: 0.0957 - val_accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 11:13:38.108448: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-01-10 11:13:38.580137: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-10 11:13:38.580185: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-01-10 11:13:38.581203: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-10 11:13:39.204819: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-10 11:13:42.670285: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-10 11:13:42.670331: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-01-10 11:13:42.731554: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-01-10 11:13:42.741425: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-10 11:13:42.758424: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: mnist_models/models/cnn_20220110_111330/train/plugins/profile/2022_01_10_11_13_42\n",
      "\n",
      "2022-01-10 11:13:42.763094: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to mnist_models/models/cnn_20220110_111330/train/plugins/profile/2022_01_10_11_13_42/tensorflow-2-6-20220110-155153.trace.json.gz\n",
      "2022-01-10 11:13:42.794321: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: mnist_models/models/cnn_20220110_111330/train/plugins/profile/2022_01_10_11_13_42\n",
      "\n",
      "2022-01-10 11:13:42.797500: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to mnist_models/models/cnn_20220110_111330/train/plugins/profile/2022_01_10_11_13_42/tensorflow-2-6-20220110-155153.memory_profile.json.gz\n",
      "2022-01-10 11:13:42.799522: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: mnist_models/models/cnn_20220110_111330/train/plugins/profile/2022_01_10_11_13_42\n",
      "Dumped tool data for xplane.pb to mnist_models/models/cnn_20220110_111330/train/plugins/profile/2022_01_10_11_13_42/tensorflow-2-6-20220110-155153.xplane.pb\n",
      "Dumped tool data for overview_page.pb to mnist_models/models/cnn_20220110_111330/train/plugins/profile/2022_01_10_11_13_42/tensorflow-2-6-20220110-155153.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to mnist_models/models/cnn_20220110_111330/train/plugins/profile/2022_01_10_11_13_42/tensorflow-2-6-20220110-155153.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to mnist_models/models/cnn_20220110_111330/train/plugins/profile/2022_01_10_11_13_42/tensorflow-2-6-20220110-155153.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to mnist_models/models/cnn_20220110_111330/train/plugins/profile/2022_01_10_11_13_42/tensorflow-2-6-20220110-155153.kernel_stats.pb\n",
      "\n",
      "2022-01-10 11:14:20.832201: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 -m mnist_models.trainer.task \\\n",
    "    --job-dir=$JOB_DIR \\\n",
    "    --epochs=5 \\\n",
    "    --steps_per_epoch=50 \\\n",
    "    --model_type=$MODEL_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the cloud\n",
    "\n",
    "For this model, you use a Tensorflow pre-built container on Vertex AI, as you do not have any particular additional prerequisites. You use setuptools for this, and store the created source distribution on Cloud Storage by using “**gsutil cp**”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mnist_models/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_models/setup.py\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "\n",
    "setup(\n",
    "    name='mnist_trainer',\n",
    "    version='0.1',\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='MNIST model training application.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "creating mnist_trainer.egg-info\n",
      "writing mnist_trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to mnist_trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to mnist_trainer.egg-info/top_level.txt\n",
      "writing manifest file 'mnist_trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'mnist_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'mnist_trainer.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating mnist_trainer-0.1\n",
      "creating mnist_trainer-0.1/mnist_trainer.egg-info\n",
      "creating mnist_trainer-0.1/trainer\n",
      "copying files to mnist_trainer-0.1...\n",
      "copying setup.py -> mnist_trainer-0.1\n",
      "copying mnist_trainer.egg-info/PKG-INFO -> mnist_trainer-0.1/mnist_trainer.egg-info\n",
      "copying mnist_trainer.egg-info/SOURCES.txt -> mnist_trainer-0.1/mnist_trainer.egg-info\n",
      "copying mnist_trainer.egg-info/dependency_links.txt -> mnist_trainer-0.1/mnist_trainer.egg-info\n",
      "copying mnist_trainer.egg-info/top_level.txt -> mnist_trainer-0.1/mnist_trainer.egg-info\n",
      "copying trainer/__init__.py -> mnist_trainer-0.1/trainer\n",
      "copying trainer/model.py -> mnist_trainer-0.1/trainer\n",
      "copying trainer/task.py -> mnist_trainer-0.1/trainer\n",
      "copying trainer/test.py -> mnist_trainer-0.1/trainer\n",
      "copying trainer/util.py -> mnist_trainer-0.1/trainer\n",
      "Writing mnist_trainer-0.1/setup.cfg\n",
      "creating dist\n",
      "Creating tar archive\n",
      "removing 'mnist_trainer-0.1' (and everything under it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "Copying file://mnist_models/dist/mnist_trainer-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  3.2 KiB/  3.2 KiB]                                                \n",
      "Operation completed over 1 objects/3.2 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd mnist_models\n",
    "python ./setup.py sdist --formats=gztar\n",
    "cd ..\n",
    "gsutil cp mnist_models/dist/mnist_trainer-0.1.tar.gz gs://${BUCKET}/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can start the Vertex AI Custom Job using the pre-built container. You can pass your source distribution URI using the --python-package-uris flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_type = 'cnn'\n",
    "\n",
    "os.environ[\"MODEL_TYPE\"] = model_type\n",
    "os.environ[\"JOB_DIR\"] = \"gs://{}/mnist_{}_{}/\".format(\n",
    "    BUCKET, model_type, current_time)\n",
    "os.environ[\"JOB_NAME\"] = \"mnist_{}_{}\".format(\n",
    "    model_type, current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting the following job, view the status in __Vertex AI__ > __Training__ and select __Custom Jobs__ tab. Wait for the job to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-04-25783cd152f3/mnist_cnn_20220110_112058/ us-central1 mnist_cnn_20220110_112058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "CustomJob [projects/867925218804/locations/us-central1/customJobs/3584008783828877312] is submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs describe projects/867925218804/locations/us-central1/customJobs/3584008783828877312\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs stream-logs projects/867925218804/locations/us-central1/customJobs/3584008783828877312\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $JOB_DIR $REGION $JOB_NAME\n",
    "\n",
    "PYTHON_PACKAGE_URIS=gs://${BUCKET}/mnist/mnist_trainer-0.1.tar.gz\n",
    "MACHINE_TYPE=n1-standard-4\n",
    "REPLICA_COUNT=1\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-3:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "    \n",
    "WORKER_POOL_SPEC=\"machine-type=$MACHINE_TYPE,\\\n",
    "replica-count=$REPLICA_COUNT,\\\n",
    "executor-image-uri=$PYTHON_PACKAGE_EXECUTOR_IMAGE_URI,\\\n",
    "python-module=$PYTHON_MODULE\"\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --python-package-uris=$PYTHON_PACKAGE_URIS \\\n",
    "  --worker-pool-spec=$WORKER_POOL_SPEC \\\n",
    "  --args=\"--job-dir=$JOB_DIR,--model_type=$MODEL_TYPE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-04-25783cd152f3/mnist_cnn_20220110_112058/keras_export\n",
      "gs://qwiklabs-gcp-04-25783cd152f3/mnist_cnn_20220110_112058/keras_export/\n",
      "gs://qwiklabs-gcp-04-25783cd152f3/mnist_cnn_20220110_112058/keras_export/saved_model.pb\n",
      "gs://qwiklabs-gcp-04-25783cd152f3/mnist_cnn_20220110_112058/keras_export/assets/\n",
      "gs://qwiklabs-gcp-04-25783cd152f3/mnist_cnn_20220110_112058/keras_export/variables/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "SAVEDMODEL_DIR=${JOB_DIR}keras_export\n",
    "echo $SAVEDMODEL_DIR\n",
    "gsutil ls $SAVEDMODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Once you have a model you're proud of, let's deploy it! All you need to do is to upload the created model artifact from Cloud Storage to Vertex AI as a model, create a new endpoint, and deploy the model to the endpoint. It can take 15-20 minutes to complete. Make a note of **ENDPOINT_RESOURCENAME** for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-04-25783cd152f3/mnist_cnn_20220110_112058/keras_export\n",
      "MODEL_DISPLAYNAME=mnist_20220110_113117\n",
      "MODEL_RESOURCENAME=projects/867925218804/locations/us-central1/models/5397040785868718080\n",
      "ENDPOINT_DISPLAYNAME=mnist_endpoint_20220110_113117\n",
      "ENDPOINT_RESOURCENAME=projects/867925218804/locations/us-central1/endpoints/2075394168124866560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [3241482393193807872]...\n",
      "...................done.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [4016101529101533184]...\n",
      ".....................................done.\n",
      "Created Vertex AI endpoint: projects/867925218804/locations/us-central1/endpoints/2075394168124866560.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [5430231812095868928]...\n",
      ".....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n",
      "Deployed a model to the endpoint 2075394168124866560. Id of the deployed model: 7191377791701483520.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "MODEL_DISPLAYNAME=mnist_$TIMESTAMP\n",
    "ENDPOINT_DISPLAYNAME=mnist_endpoint_$TIMESTAMP\n",
    "IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-3:latest\"\n",
    "SAVEDMODEL_DIR=${JOB_DIR}keras_export\n",
    "echo $SAVEDMODEL_DIR\n",
    "\n",
    "# Model\n",
    "MODEL_RESOURCENAME=$(gcloud ai models upload \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$MODEL_DISPLAYNAME \\\n",
    "    --container-image-uri=$IMAGE_URI \\\n",
    "    --artifact-uri=$SAVEDMODEL_DIR \\\n",
    "    --format=\"value(model)\")\n",
    "\n",
    "echo \"MODEL_DISPLAYNAME=${MODEL_DISPLAYNAME}\"\n",
    "echo \"MODEL_RESOURCENAME=${MODEL_RESOURCENAME}\"\n",
    "\n",
    "# Endpoint\n",
    "ENDPOINT_RESOURCENAME=$(gcloud ai endpoints create \\\n",
    "  --region=$REGION \\\n",
    "  --display-name=$ENDPOINT_DISPLAYNAME \\\n",
    "  --format=\"value(name)\")\n",
    "\n",
    "echo \"ENDPOINT_DISPLAYNAME=${ENDPOINT_DISPLAYNAME}\"\n",
    "echo \"ENDPOINT_RESOURCENAME=${ENDPOINT_RESOURCENAME}\"\n",
    "\n",
    "# Deployment\n",
    "DEPLOYED_MODEL_DISPLAYNAME=${MODEL_DISPLAYNAME}_deployment\n",
    "MACHINE_TYPE=n1-standard-2\n",
    "\n",
    "gcloud ai endpoints deploy-model $ENDPOINT_RESOURCENAME \\\n",
    "  --region=$REGION \\\n",
    "  --model=$MODEL_RESOURCENAME \\\n",
    "  --display-name=$DEPLOYED_MODEL_DISPLAYNAME \\\n",
    "  --machine-type=$MACHINE_TYPE \\\n",
    "  --min-replica-count=1 \\\n",
    "  --max-replica-count=1 \\\n",
    "  --traffic-split=0=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with the model, take one of the example images.\n",
    "\n",
    "Write a .json file with image data to send to a Vertex AI deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json, codecs\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "IMGNO = 12\n",
    "\n",
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "test_image = x_test[IMGNO]\n",
    "\n",
    "# TODO 4: Prepare jsondata\n",
    "jsondata = {\"instances\": [\n",
    "    test_image.reshape(HEIGHT, WIDTH, 1).tolist()\n",
    "]}\n",
    "json.dump(jsondata, codecs.open(\"test.json\", \"w\", encoding = \"utf-8\"))\n",
    "plt.imshow(test_image.reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"instances\": [[[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [49], [180], [253], [255], [253], [169], [36], [11], [76], [9], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [5], [68], [228], [252], [252], [253], [252], [252], [160], [189], [253], [92], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [55], [252], [252], [227], [79], [69], [69], [100], [90], [236], [247], [67], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [43], [233], [252], [185], [50], [0], [0], [0], [26], [203], [252], [135], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [168], [253], [178], [37], [0], [0], [0], [0], [70], [252], [252], [63], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [155], [253], [242], [42], [0], [0], [0], [0], [5], [191], [253], [190], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [207], [252], [230], [0], [0], [0], [0], [5], [136], [252], [252], [64], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [207], [252], [230], [0], [0], [0], [32], [138], [252], [252], [227], [16], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [165], [252], [249], [207], [207], [207], [228], [253], [252], [252], [160], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [9], [179], [253], [252], [252], [252], [252], [75], [169], [252], [56], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [64], [116], [116], [74], [0], [149], [253], [215], [21], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [253], [252], [162], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [32], [253], [240], [50], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [157], [253], [164], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [43], [240], [253], [92], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [93], [253], [252], [84], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [114], [252], [209], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [207], [252], [116], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [165], [252], [116], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [93], [200], [63], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]]]}"
     ]
    }
   ],
   "source": [
    "!cat test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can send it to the prediction service. The output will have a 1 in the index of the corresponding digit it is predicting. Congrats! You've completed the lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ENDPOINT_RESOURCENAME=#Insert ENDPOINT_RESOURCENAME from above\n",
    "\n",
    "gcloud ai endpoints predict $ENDPOINT_RESOURCENAME \\\n",
    "    --region=$REGION \\\n",
    "    --json-request=test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-6:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
